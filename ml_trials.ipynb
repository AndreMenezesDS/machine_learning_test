{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i. BUSINESS JOB DESCRIPTION\n",
    "\n",
    "*   Data Money is a company that offers data analysis consultancy services, guided towards other partner companies worldwide.\n",
    "*   The main feature on Data Money services resides on the metodology used on training and tunning machine learning models, a task properly achieved by their team of Data Scientists, clarifying the behaviour of each algorithm with proven explained results.\n",
    "\n",
    "# ii. THE CHALLENGE\n",
    "\n",
    "*   In order to keep the company's data scientists team growth in performance, Data Money required the execution of a higher number of model trials, with goals of further understanding which were the adequate scenarios to apply each algorithm. These choices are then expected to be based upon the showcasing of verified metrics, serving as means of comparisons between machine learning models to know when their performance is best optimized/minimized.\n",
    "*   Being a Data Scientist recently hired by the company, I was then tasked of realizing trials for Classification, Regression and clustering machine learning models, to further report their results to the other working teams.\n",
    "\n",
    "# iii. BUSINESS CHALLANGE SPECIFICATIONS\n",
    "\n",
    "*   It is expected to verify the performance results on 3 different datasets, those being:\n",
    "    1. The training dataset (Used for both training and model prediction)\n",
    "    2. Validation Dataset\n",
    "    3. Test Dataset\n",
    "\n",
    "\n",
    "*   The results will then be reported as a table for each different dataset, containing the comparison of metrics for a selection of machine learning models.\n",
    "*   The only exception will be the analysis for clustering model: Given that it is an unsupervized learning model, it will then be only one table containing its results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 IMPORTS AND HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.neighbors      import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree           import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble       import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model   import LogisticRegression, LinearRegression, Lasso, Ridge, ElasticNet\n",
    "\n",
    "from sklearn                import preprocessing as pp\n",
    "from sklearn                import cluster as c\n",
    "from sklearn                import metrics as mt\n",
    "from sklearn                import model_selection as ms \n",
    "from sklearn                import datasets as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 CLASSIFICATION MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   The main metric used for evaluation on overall model performance will be the f1_score, since it considers an equilibrium on both precision and recall metrics.\n",
    "*   Accuracy, precision and recall scores will also be listed, as well as the hyperparameter set tunned for each iteration, in order to obtain insights on how each model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training_classification = pd.read_csv('datasets\\classification\\X_training.csv')\n",
    "y_training_classification = pd.read_csv('datasets\\classification\\y_training.csv')\n",
    "\n",
    "X_validation_classification = pd.read_csv('datasets\\classification\\X_validation.csv')\n",
    "y_validation_classification = pd.read_csv('datasets\\classification\\y_validation.csv')\n",
    "\n",
    "X_test_classification = pd.read_csv('datasets\\classification\\X_test.csv')\n",
    "y_test_classification = pd.read_csv('datasets\\classification\\y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: rows = 72515, columns = 25\n",
      "Validation dataset: rows = 31079, columns = 25\n",
      "Test dataset: rows = 25893, columns = 25\n",
      "Number of classes:2, Distinct Classes:[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(f'Training dataset: rows = {X_training_classification.shape[0]}, columns = {X_training_classification.shape[1]}')\n",
    "print(f'Validation dataset: rows = {X_validation_classification.shape[0]}, columns = {X_validation_classification.shape[1]}')\n",
    "print(f'Test dataset: rows = {X_test_classification.shape[0]}, columns = {X_test_classification.shape[1]}')\n",
    "\n",
    "print(f'Number of classes:{len(np.unique(y_training_classification))}, Distinct Classes:{np.unique(y_training_classification)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Every class variable array ('y' variables), matches in size with their features counterparts('x' variables).\n",
    "*   The datasets are presented as being binary classed, with '0' and '1' as the class variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours_list = list()\n",
    "\n",
    "acc_list_training = list()\n",
    "precision_list_training = list()\n",
    "recall_list_training = list()\n",
    "f1_list_training = list()\n",
    "\n",
    "acc_list_validation = list()\n",
    "precision_list_validation = list()\n",
    "recall_list_validation = list()\n",
    "f1_list_validation = list()\n",
    "\n",
    "acc_list_test = list()\n",
    "precision_list_test = list()\n",
    "recall_list_test = list()\n",
    "f1_list_test = list()\n",
    "\n",
    "for i in range(3, 15, 2):\n",
    "    neighbours_list.append(i)\n",
    "    #Model Definition\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = i)\n",
    "    \n",
    "    #Model Train\n",
    "    knn_classifier.fit(X_training_classification, np.ravel(y_training_classification))\n",
    "    \n",
    "    #Model Predict\n",
    "    yhat_knn_training   = knn_classifier.predict(X_training_classification)\n",
    "    yhat_knn_validation = knn_classifier.predict(X_validation_classification)\n",
    "    yhat_knn_test       = knn_classifier.predict(X_test_classification)\n",
    "    \n",
    "    #training scores\n",
    "    acc_score_training       = mt.accuracy_score(y_training_classification, yhat_knn_training)\n",
    "    precision_score_training = mt.precision_score(y_training_classification, yhat_knn_training)\n",
    "    recall_score_training    = mt.recall_score(y_training_classification, yhat_knn_training)\n",
    "    f1_score_training        = mt.f1_score(y_training_classification, yhat_knn_training)\n",
    "    \n",
    "    acc_list_training.append(acc_score_training)\n",
    "    precision_list_training.append(precision_score_training)\n",
    "    recall_list_training.append(recall_score_training)\n",
    "    f1_list_training.append(f1_score_training)\n",
    "    \n",
    "    #validation scores\n",
    "    acc_score_validation       = mt.accuracy_score(y_validation_classification, yhat_knn_validation)\n",
    "    precision_score_validation = mt.precision_score(y_validation_classification, yhat_knn_validation)\n",
    "    recall_score_validation    = mt.recall_score(y_validation_classification, yhat_knn_validation)\n",
    "    f1_score_validation        = mt.f1_score(y_validation_classification, yhat_knn_validation)\n",
    "    \n",
    "    acc_list_validation.append(acc_score_validation)\n",
    "    precision_list_validation.append(precision_score_validation)\n",
    "    recall_list_validation.append(recall_score_validation)\n",
    "    f1_list_validation.append(f1_score_validation)\n",
    "    \n",
    "    #test scores\n",
    "    acc_score_test       = mt.accuracy_score(y_test_classification, yhat_knn_test)\n",
    "    precision_score_test = mt.precision_score(y_test_classification, yhat_knn_test)\n",
    "    recall_score_test    = mt.recall_score(y_test_classification, yhat_knn_test)\n",
    "    f1_score_test        = mt.f1_score(y_test_classification, yhat_knn_test)\n",
    "    \n",
    "    acc_list_test.append(acc_score_test)\n",
    "    precision_list_test.append(precision_score_test)\n",
    "    recall_list_test.append(recall_score_test)\n",
    "    f1_list_test.append(f1_score_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbors</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.832186</td>\n",
       "      <td>0.812008</td>\n",
       "      <td>0.79741</td>\n",
       "      <td>0.804643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbors  accuracy_score  precision_score  recall_score  f1_score\n",
       "0          3        0.832186         0.812008       0.79741  0.804643"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_training_df = pd.DataFrame({'neighbors': neighbours_list, 'accuracy_score':acc_list_training, \n",
    "                                'precision_score': precision_list_training, 'recall_score':recall_list_training, \n",
    "                                'f1_score':f1_list_training})\n",
    "\n",
    "knn_training_max = knn_training_df.query('f1_score == f1_score.max()')\n",
    "knn_training_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbors</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.676277</td>\n",
       "      <td>0.627851</td>\n",
       "      <td>0.621278</td>\n",
       "      <td>0.624548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbors  accuracy_score  precision_score  recall_score  f1_score\n",
       "0          3        0.676277         0.627851      0.621278  0.624548"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_validation_df = pd.DataFrame({'neighbors': neighbours_list, 'accuracy_score':acc_list_validation, \n",
    "                                'precision_score': precision_list_validation, 'recall_score':recall_list_validation, \n",
    "                                'f1_score':f1_list_validation})\n",
    "\n",
    "knn_validation_max = knn_validation_df.query('f1_score == f1_score.max()')\n",
    "knn_validation_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbors</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.672228</td>\n",
       "      <td>0.630462</td>\n",
       "      <td>0.611879</td>\n",
       "      <td>0.621031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbors  accuracy_score  precision_score  recall_score  f1_score\n",
       "0          3        0.672228         0.630462      0.611879  0.621031"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_test_df = pd.DataFrame({'neighbors': neighbours_list, 'accuracy_score':acc_list_test, \n",
    "                            'precision_score': precision_list_test, 'recall_score':recall_list_test, \n",
    "                            'f1_score':f1_list_test})\n",
    "\n",
    "knn_test_max = knn_test_df.query('f1_score == f1_score.max()')\n",
    "knn_test_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   All datasets presented optimal results for lower number of neighbors, justifying the choice for n_neighbors=3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = list()\n",
    "\n",
    "acc_list_training = list()\n",
    "precision_list_training = list()\n",
    "recall_list_training = list()\n",
    "f1_list_training = list()\n",
    "\n",
    "acc_list_validation = list()\n",
    "precision_list_validation = list()\n",
    "recall_list_validation = list()\n",
    "f1_list_validation = list()\n",
    "\n",
    "acc_list_test = list()\n",
    "precision_list_test = list()\n",
    "recall_list_test = list()\n",
    "f1_list_test = list()\n",
    "\n",
    "for i in range(1, 20, 2):\n",
    "    max_depth_list.append(i)\n",
    "    #Model Define\n",
    "    model_tree = DecisionTreeClassifier(max_depth=i, random_state=42)\n",
    "    \n",
    "    #Model Training\n",
    "    model_tree.fit(X_training_classification, np.ravel(y_training_classification))\n",
    "    \n",
    "    #Model Predict\n",
    "    yhat_tree_training   = model_tree.predict(X_training_classification)\n",
    "    yhat_tree_validation = model_tree.predict(X_validation_classification)\n",
    "    yhat_tree_test       = model_tree.predict(X_test_classification)\n",
    "    \n",
    "    #training scores\n",
    "    acc_score_training       = mt.accuracy_score(y_training_classification, yhat_tree_training)\n",
    "    precision_score_training = mt.precision_score(y_training_classification, yhat_tree_training)\n",
    "    recall_score_training    = mt.recall_score(y_training_classification, yhat_tree_training)\n",
    "    f1_score_training        = mt.f1_score(y_training_classification, yhat_tree_training)\n",
    "    \n",
    "    acc_list_training.append(acc_score_training)\n",
    "    precision_list_training.append(precision_score_training)\n",
    "    recall_list_training.append(recall_score_training)\n",
    "    f1_list_training.append(f1_score_training)\n",
    "    \n",
    "    #validation scores\n",
    "    acc_score_validation       = mt.accuracy_score(y_validation_classification, yhat_tree_validation)\n",
    "    precision_score_validation = mt.precision_score(y_validation_classification, yhat_tree_validation)\n",
    "    recall_score_validation    = mt.recall_score(y_validation_classification, yhat_tree_validation)\n",
    "    f1_score_validation        = mt.f1_score(y_validation_classification, yhat_tree_validation)\n",
    "    \n",
    "    acc_list_validation.append(acc_score_validation)\n",
    "    precision_list_validation.append(precision_score_validation)\n",
    "    recall_list_validation.append(recall_score_validation)\n",
    "    f1_list_validation.append(f1_score_validation)\n",
    "    \n",
    "    #test scores\n",
    "    acc_score_test       = mt.accuracy_score(y_test_classification, yhat_tree_test)\n",
    "    precision_score_test = mt.precision_score(y_test_classification, yhat_tree_test)\n",
    "    recall_score_test    = mt.recall_score(y_test_classification, yhat_tree_test)\n",
    "    f1_score_test        = mt.f1_score(y_test_classification, yhat_tree_test)\n",
    "    \n",
    "    acc_list_test.append(acc_score_test)\n",
    "    precision_list_test.append(precision_score_test)\n",
    "    recall_list_test.append(recall_score_test)\n",
    "    f1_list_test.append(f1_score_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.989712</td>\n",
       "      <td>0.993089</td>\n",
       "      <td>0.983104</td>\n",
       "      <td>0.988072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  accuracy_score  precision_score  recall_score  f1_score\n",
       "9         19        0.989712         0.993089      0.983104  0.988072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_training_df = pd.DataFrame({'max_depth': max_depth_list, 'accuracy_score':acc_list_training, \n",
    "                                'precision_score': precision_list_training, 'recall_score':recall_list_training, \n",
    "                                'f1_score':f1_list_training})\n",
    "\n",
    "tree_training_max = tree_training_df.query('f1_score == f1_score.max()')\n",
    "tree_training_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.952315</td>\n",
       "      <td>0.9563</td>\n",
       "      <td>0.932586</td>\n",
       "      <td>0.944294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  accuracy_score  precision_score  recall_score  f1_score\n",
       "6         13        0.952315           0.9563      0.932586  0.944294"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_validation_df = pd.DataFrame({'max_depth': max_depth_list, 'accuracy_score':acc_list_validation, \n",
    "                                   'precision_score': precision_list_validation, 'recall_score':recall_list_validation, \n",
    "                                   'f1_score':f1_list_validation})\n",
    "\n",
    "tree_validation_max = tree_validation_df.query('f1_score == f1_score.max()')\n",
    "tree_validation_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.951802</td>\n",
       "      <td>0.953881</td>\n",
       "      <td>0.935416</td>\n",
       "      <td>0.944558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  accuracy_score  precision_score  recall_score  f1_score\n",
       "6         13        0.951802         0.953881      0.935416  0.944558"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_test_df = pd.DataFrame({'max_depth': max_depth_list, 'accuracy_score':acc_list_test, \n",
    "                                'precision_score': precision_list_test, 'recall_score':recall_list_test, \n",
    "                                'f1_score':f1_list_test})\n",
    "\n",
    "tree_test_max = tree_test_df.query('f1_score == f1_score.max()')\n",
    "tree_test_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   While validating results using only the training dataset, we can infer that all metrics(including f1_score) grow indefenitely to 100% as the depth of the tree increases, indicating an overfitting behaviour.\n",
    "*   For Validation and Test datasets however, model performance reaches its peak on max_depth=13, indicating that there is no more gain of information for these datasets beyond this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': [1, 10, 50, 100, 150, 200],\n",
    "          'max_depth': [1, 5, 10, 15, 20]}\n",
    "\n",
    "n_estimators_list = list()\n",
    "max_depth_list = list()\n",
    "\n",
    "acc_list_training = list()\n",
    "precision_list_training = list()\n",
    "recall_list_training = list()\n",
    "f1_list_training = list()\n",
    "\n",
    "acc_list_validation = list()\n",
    "precision_list_validation = list()\n",
    "recall_list_validation = list()\n",
    "f1_list_validation = list()\n",
    "\n",
    "acc_list_test = list()\n",
    "precision_list_test = list()\n",
    "recall_list_test = list()\n",
    "f1_list_test = list()\n",
    "\n",
    "\n",
    "for i in params.get('n_estimators'):\n",
    "    for j in params.get('max_depth'):\n",
    "        n_estimators_list.append(i)\n",
    "        max_depth_list.append(j)\n",
    "        #Model Definition\n",
    "        rf_model = RandomForestClassifier(n_estimators=i, max_depth=j, random_state=42)\n",
    "\n",
    "        #Model Training\n",
    "        rf_model.fit(X_training_classification, np.ravel(y_training_classification))\n",
    "\n",
    "        #Model Predict\n",
    "        yhat_rf_training    = rf_model.predict(X_training_classification)\n",
    "        yhat_rf_validation  = rf_model.predict(X_validation_classification)\n",
    "        yhat_rf_test        = rf_model.predict(X_test_classification)\n",
    "\n",
    "        #Model Scores\n",
    "        #training scores\n",
    "        acc_score_training       = mt.accuracy_score(y_training_classification, yhat_rf_training)\n",
    "        precision_score_training = mt.precision_score(y_training_classification, yhat_rf_training)\n",
    "        recall_score_training    = mt.recall_score(y_training_classification, yhat_rf_training)\n",
    "        f1_score_training        = mt.f1_score(y_training_classification, yhat_rf_training)\n",
    "    \n",
    "        acc_list_training.append(acc_score_training)\n",
    "        precision_list_training.append(precision_score_training)\n",
    "        recall_list_training.append(recall_score_training)\n",
    "        f1_list_training.append(f1_score_training)\n",
    "    \n",
    "        #validation scores\n",
    "        acc_score_validation       = mt.accuracy_score(y_validation_classification, yhat_rf_validation)\n",
    "        precision_score_validation = mt.precision_score(y_validation_classification, yhat_rf_validation)\n",
    "        recall_score_validation    = mt.recall_score(y_validation_classification, yhat_rf_validation)\n",
    "        f1_score_validation        = mt.f1_score(y_validation_classification, yhat_rf_validation)\n",
    "    \n",
    "        acc_list_validation.append(acc_score_validation)\n",
    "        precision_list_validation.append(precision_score_validation)\n",
    "        recall_list_validation.append(recall_score_validation)\n",
    "        f1_list_validation.append(f1_score_validation)\n",
    "\n",
    "        #test scores\n",
    "        acc_score_test       = mt.accuracy_score(y_test_classification, yhat_rf_test)\n",
    "        precision_score_test = mt.precision_score(y_test_classification, yhat_rf_test)\n",
    "        recall_score_test    = mt.recall_score(y_test_classification, yhat_rf_test)\n",
    "        f1_score_test        = mt.f1_score(y_test_classification, yhat_rf_test)\n",
    "    \n",
    "        acc_list_test.append(acc_score_test)\n",
    "        precision_list_test.append(precision_score_test)\n",
    "        recall_list_test.append(recall_score_test)\n",
    "        f1_list_test.append(f1_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>0.996525</td>\n",
       "      <td>0.998242</td>\n",
       "      <td>0.993732</td>\n",
       "      <td>0.995982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  n_estimators  accuracy_score  precision_score  recall_score  \\\n",
       "24         20           150        0.996525         0.998242      0.993732   \n",
       "\n",
       "    f1_score  \n",
       "24  0.995982  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_training_df = pd.DataFrame({'max_depth': max_depth_list, 'n_estimators':n_estimators_list,\n",
    "                               'accuracy_score':acc_list_training, 'precision_score': precision_list_training,\n",
    "                               'recall_score':recall_list_training, 'f1_score':f1_list_training})\n",
    "\n",
    "\n",
    "rf_training_max = rf_training_df.query('f1_score == f1_score.max()')\n",
    "rf_training_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>0.965185</td>\n",
       "      <td>0.974271</td>\n",
       "      <td>0.944614</td>\n",
       "      <td>0.959213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  n_estimators  accuracy_score  precision_score  recall_score  \\\n",
       "29         20           200        0.965185         0.974271      0.944614   \n",
       "\n",
       "    f1_score  \n",
       "29  0.959213  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_validation_df = pd.DataFrame({'max_depth': max_depth_list, 'n_estimators':n_estimators_list,\n",
    "                               'accuracy_score':acc_list_validation, 'precision_score': precision_list_validation,\n",
    "                               'recall_score':recall_list_validation, 'f1_score':f1_list_validation})\n",
    "\n",
    "rf_validation_max = rf_validation_df.query('f1_score == f1_score.max()')\n",
    "rf_validation_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>0.963928</td>\n",
       "      <td>0.971777</td>\n",
       "      <td>0.945271</td>\n",
       "      <td>0.958341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  n_estimators  accuracy_score  precision_score  recall_score  \\\n",
       "24         20           150        0.963928         0.971777      0.945271   \n",
       "\n",
       "    f1_score  \n",
       "24  0.958341  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test_df = pd.DataFrame({'max_depth': max_depth_list, 'n_estimators':n_estimators_list,\n",
    "                               'accuracy_score':acc_list_test, 'precision_score': precision_list_test,\n",
    "                               'recall_score':recall_list_test, 'f1_score':f1_list_test})\n",
    "\n",
    "rf_test_max = rf_test_df.query('f1_score == f1_score.max()')\n",
    "rf_test_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Alike the Decision Tree results, a tree based model such as the Random Forest tend to overfit as you increase the number of estimators as well as tree max depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':[0.1, 0.5, 1.0, 2.0],\n",
    "          'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "          'max_iter': [50, 100, 150, 200]}\n",
    "\n",
    "c_estimator_list = list()\n",
    "solver_estimator_list = list()\n",
    "max_iter_estimator_list = list()\n",
    "\n",
    "acc_list_training = list()\n",
    "precision_list_training = list()\n",
    "recall_list_training = list()\n",
    "f1_list_training = list()\n",
    "\n",
    "acc_list_validation = list()\n",
    "precision_list_validation = list()\n",
    "recall_list_validation = list()\n",
    "f1_list_validation = list()\n",
    "\n",
    "acc_list_test = list()\n",
    "precision_list_test = list()\n",
    "recall_list_test = list()\n",
    "f1_list_test = list()\n",
    "\n",
    "for i in params.get('C'):\n",
    "    for j in params.get('solver'):\n",
    "        for p in params.get('max_iter'):\n",
    "            c_estimator_list.append(i)\n",
    "            solver_estimator_list.append(j)\n",
    "            max_iter_estimator_list.append(p)\n",
    "            \n",
    "            #Model Define\n",
    "            lr_model = LogisticRegression(C=i, solver=j, max_iter=p, random_state=42)\n",
    "            \n",
    "            #Model Training\n",
    "            lr_model.fit(X_training_classification, np.ravel(y_training_classification))\n",
    "            \n",
    "            #Model Predict\n",
    "            yhat_lr_training    = lr_model.predict(X_training_classification)\n",
    "            yhat_lr_validation  = lr_model.predict(X_validation_classification)\n",
    "            yhat_lr_test        = lr_model.predict(X_test_classification)\n",
    "            \n",
    "            #Model Scores\n",
    "            #Training Scores\n",
    "            acc_score_training       = mt.accuracy_score(y_training_classification, yhat_lr_training)\n",
    "            precision_score_training = mt.precision_score(y_training_classification, yhat_lr_training)\n",
    "            recall_score_training    = mt.recall_score(y_training_classification, yhat_lr_training)\n",
    "            f1_score_training        = mt.f1_score(y_training_classification, yhat_lr_training)\n",
    "    \n",
    "            acc_list_training.append(acc_score_training)\n",
    "            precision_list_training.append(precision_score_training)\n",
    "            recall_list_training.append(recall_score_training)\n",
    "            f1_list_training.append(f1_score_training)\n",
    "            \n",
    "            #Validation Scores\n",
    "            acc_score_validation       = mt.accuracy_score(y_validation_classification, yhat_lr_validation)\n",
    "            precision_score_validation = mt.precision_score(y_validation_classification, yhat_lr_validation)\n",
    "            recall_score_validation    = mt.recall_score(y_validation_classification, yhat_lr_validation)\n",
    "            f1_score_validation        = mt.f1_score(y_validation_classification, yhat_lr_validation)\n",
    "    \n",
    "            acc_list_validation.append(acc_score_validation)\n",
    "            precision_list_validation.append(precision_score_validation)\n",
    "            recall_list_validation.append(recall_score_validation)\n",
    "            f1_list_validation.append(f1_score_validation)\n",
    "            \n",
    "            #Test Scores\n",
    "            acc_score_test       = mt.accuracy_score(y_test_classification, yhat_lr_test)\n",
    "            precision_score_test = mt.precision_score(y_test_classification, yhat_lr_test)\n",
    "            recall_score_test    = mt.recall_score(y_test_classification, yhat_lr_test)\n",
    "            f1_score_test        = mt.f1_score(y_test_classification, yhat_lr_test)\n",
    "    \n",
    "            acc_list_test.append(acc_score_test)\n",
    "            precision_list_test.append(precision_score_test)\n",
    "            recall_list_test.append(recall_score_test)\n",
    "            f1_list_test.append(f1_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.876288</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.837661</td>\n",
       "      <td>0.854421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>150</td>\n",
       "      <td>0.876288</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.837661</td>\n",
       "      <td>0.854421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>200</td>\n",
       "      <td>0.876288</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.837661</td>\n",
       "      <td>0.854421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>50</td>\n",
       "      <td>0.876288</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.837661</td>\n",
       "      <td>0.854421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>100</td>\n",
       "      <td>0.876288</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.837661</td>\n",
       "      <td>0.854421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>150</td>\n",
       "      <td>0.876288</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.837661</td>\n",
       "      <td>0.854421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>200</td>\n",
       "      <td>0.876288</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.837661</td>\n",
       "      <td>0.854421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C           solver  max_iter  accuracy_score  precision_score  \\\n",
       "9   0.1        newton-cg       100        0.876288         0.871866   \n",
       "10  0.1        newton-cg       150        0.876288         0.871866   \n",
       "11  0.1        newton-cg       200        0.876288         0.871866   \n",
       "12  0.1  newton-cholesky        50        0.876288         0.871866   \n",
       "13  0.1  newton-cholesky       100        0.876288         0.871866   \n",
       "14  0.1  newton-cholesky       150        0.876288         0.871866   \n",
       "15  0.1  newton-cholesky       200        0.876288         0.871866   \n",
       "\n",
       "    recall_score  f1_score  \n",
       "9       0.837661  0.854421  \n",
       "10      0.837661  0.854421  \n",
       "11      0.837661  0.854421  \n",
       "12      0.837661  0.854421  \n",
       "13      0.837661  0.854421  \n",
       "14      0.837661  0.854421  \n",
       "15      0.837661  0.854421  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_training_df = pd.DataFrame({'C': c_estimator_list, 'solver':solver_estimator_list, 'max_iter':max_iter_estimator_list,\n",
    "                               'accuracy_score':acc_list_training, 'precision_score': precision_list_training,\n",
    "                               'recall_score':recall_list_training, 'f1_score':f1_list_training})\n",
    "\n",
    "lr_training_max = lr_training_df.query('f1_score == f1_score.max()')\n",
    "lr_training_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2.0</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.874481</td>\n",
       "      <td>0.869421</td>\n",
       "      <td>0.83592</td>\n",
       "      <td>0.852341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2.0</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>150</td>\n",
       "      <td>0.874481</td>\n",
       "      <td>0.869421</td>\n",
       "      <td>0.83592</td>\n",
       "      <td>0.852341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2.0</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>200</td>\n",
       "      <td>0.874481</td>\n",
       "      <td>0.869421</td>\n",
       "      <td>0.83592</td>\n",
       "      <td>0.852341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C     solver  max_iter  accuracy_score  precision_score  recall_score  \\\n",
       "81  2.0  newton-cg       100        0.874481         0.869421       0.83592   \n",
       "82  2.0  newton-cg       150        0.874481         0.869421       0.83592   \n",
       "83  2.0  newton-cg       200        0.874481         0.869421       0.83592   \n",
       "\n",
       "    f1_score  \n",
       "81  0.852341  \n",
       "82  0.852341  \n",
       "83  0.852341  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_validation_df = pd.DataFrame({'C': c_estimator_list, 'solver':solver_estimator_list, 'max_iter':max_iter_estimator_list,\n",
    "                               'accuracy_score':acc_list_validation, 'precision_score': precision_list_validation,\n",
    "                               'recall_score':recall_list_validation, 'f1_score':f1_list_validation})\n",
    "\n",
    "lr_validation_max = lr_validation_df.query('f1_score == f1_score.max()')\n",
    "lr_validation_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.5</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>50</td>\n",
       "      <td>0.871857</td>\n",
       "      <td>0.868014</td>\n",
       "      <td>0.83502</td>\n",
       "      <td>0.851197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C     solver  max_iter  accuracy_score  precision_score  recall_score  \\\n",
       "32  0.5  newton-cg        50        0.871857         0.868014       0.83502   \n",
       "\n",
       "    f1_score  \n",
       "32  0.851197  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_test_df = pd.DataFrame({'C': c_estimator_list, 'solver':solver_estimator_list, 'max_iter':max_iter_estimator_list,\n",
    "                               'accuracy_score':acc_list_test, 'precision_score': precision_list_test,\n",
    "                               'recall_score':recall_list_test, 'f1_score':f1_list_test})\n",
    "\n",
    "lr_test_max = lr_test_df.query('f1_score == f1_score.max()')\n",
    "lr_test_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   It was observed that for these datasets, the optimization algorithms that showed best performance were the ones that contain L2 penalty support. (newton-cg and newton-cholesky)\n",
    "*   Other methods (lbfgs, sag, liblinear) either failed to converge due to not approximating the cost function well or by applying a not smooth penalty(L1) to relatively small datasets(maximum 73k rows).\n",
    "*   Both C and max_iter parameters proved to be secundary upon cost function convergence, showing in comparison little influence on final metric results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Final Results for Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 Training Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_training_max = knn_training_max.drop('neighbors', axis=1)\n",
    "knn_training_max['model'] = 'KNN'\n",
    "knn_training_max = knn_training_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]\n",
    "\n",
    "#tree_training_max = tree_training_max.drop('max_depth', axis=1)\n",
    "tree_training_max['model'] = 'Decision Tree'\n",
    "tree_training_max = tree_training_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]\n",
    "\n",
    "#rf_training_max = rf_training_max.drop(['n_estimators', 'max_depth'], axis=1)\n",
    "rf_training_max['model'] = 'Random Forest'\n",
    "rf_training_max = rf_training_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]\n",
    "\n",
    "#lr_training_max = lr_training_max.drop(['C', 'solver', 'max_iter'], axis=1)\n",
    "lr_training_max['model'] = 'Logistic Regression'\n",
    "lr_training_max = lr_training_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.832186</td>\n",
       "      <td>0.812008</td>\n",
       "      <td>0.797410</td>\n",
       "      <td>0.804643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.989712</td>\n",
       "      <td>0.993089</td>\n",
       "      <td>0.983104</td>\n",
       "      <td>0.988072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.996525</td>\n",
       "      <td>0.998242</td>\n",
       "      <td>0.993732</td>\n",
       "      <td>0.995982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.876288</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.837661</td>\n",
       "      <td>0.854421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  accuracy_score  precision_score  recall_score  \\\n",
       "0                   KNN        0.832186         0.812008      0.797410   \n",
       "9         Decision Tree        0.989712         0.993089      0.983104   \n",
       "24        Random Forest        0.996525         0.998242      0.993732   \n",
       "0   Logistic Regression        0.876288         0.871866      0.837661   \n",
       "\n",
       "    f1_score  \n",
       "0   0.804643  \n",
       "9   0.988072  \n",
       "24  0.995982  \n",
       "0   0.854421  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_classification_results = pd.concat([knn_training_max, tree_training_max, rf_training_max, lr_training_max.iloc[[0]]])\n",
    "training_classification_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_validation_max = knn_validation_max.drop('neighbors', axis=1)\n",
    "knn_validation_max['model'] = 'KNN'\n",
    "knn_validation_max = knn_validation_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]\n",
    "\n",
    "#tree_validation_max = tree_validation_max.drop('max_depth', axis=1)\n",
    "tree_validation_max['model'] = 'Decision Tree'\n",
    "tree_validation_max = tree_validation_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]\n",
    "\n",
    "#rf_validation_max = rf_validation_max.drop(['n_estimators', 'max_depth'], axis=1)\n",
    "rf_validation_max['model'] = 'Random Forest'\n",
    "rf_validation_max = rf_validation_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]\n",
    "\n",
    "#lr_validation_max = lr_validation_max.drop(['C', 'solver', 'max_iter'], axis=1)\n",
    "lr_validation_max['model'] = 'Logistic Regression'\n",
    "lr_validation_max = lr_validation_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.676277</td>\n",
       "      <td>0.627851</td>\n",
       "      <td>0.621278</td>\n",
       "      <td>0.624548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.952315</td>\n",
       "      <td>0.956300</td>\n",
       "      <td>0.932586</td>\n",
       "      <td>0.944294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.965185</td>\n",
       "      <td>0.974271</td>\n",
       "      <td>0.944614</td>\n",
       "      <td>0.959213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.874481</td>\n",
       "      <td>0.869421</td>\n",
       "      <td>0.835920</td>\n",
       "      <td>0.852341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  accuracy_score  precision_score  recall_score  \\\n",
       "0                   KNN        0.676277         0.627851      0.621278   \n",
       "6         Decision Tree        0.952315         0.956300      0.932586   \n",
       "29        Random Forest        0.965185         0.974271      0.944614   \n",
       "81  Logistic Regression        0.874481         0.869421      0.835920   \n",
       "\n",
       "    f1_score  \n",
       "0   0.624548  \n",
       "6   0.944294  \n",
       "29  0.959213  \n",
       "81  0.852341  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_classification_results = pd.concat([knn_validation_max, tree_validation_max, rf_validation_max, lr_validation_max.iloc[[0]]])\n",
    "validation_classification_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3 Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_test_max = knn_test_max.drop('neighbors', axis=1)\n",
    "knn_test_max['model'] = 'KNN'\n",
    "knn_test_max = knn_test_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]\n",
    "\n",
    "#tree_test_max = tree_test_max.drop('max_depth', axis=1)\n",
    "tree_test_max['model'] = 'Decision Tree'\n",
    "tree_test_max = tree_test_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]\n",
    "\n",
    "#rf_test_max = rf_test_max.drop(['n_estimators', 'max_depth'], axis=1)\n",
    "rf_test_max['model'] = 'Random Forest'\n",
    "rf_test_max = rf_test_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]\n",
    "\n",
    "#lr_test_max = lr_test_max.drop(['C', 'solver', 'max_iter'], axis=1)\n",
    "lr_test_max['model'] = 'Logistic Regression'\n",
    "lr_test_max = lr_test_max[['model', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.672228</td>\n",
       "      <td>0.630462</td>\n",
       "      <td>0.611879</td>\n",
       "      <td>0.621031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.951802</td>\n",
       "      <td>0.953881</td>\n",
       "      <td>0.935416</td>\n",
       "      <td>0.944558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.963928</td>\n",
       "      <td>0.971777</td>\n",
       "      <td>0.945271</td>\n",
       "      <td>0.958341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.871857</td>\n",
       "      <td>0.868014</td>\n",
       "      <td>0.835020</td>\n",
       "      <td>0.851197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  accuracy_score  precision_score  recall_score  \\\n",
       "0                   KNN        0.672228         0.630462      0.611879   \n",
       "6         Decision Tree        0.951802         0.953881      0.935416   \n",
       "24        Random Forest        0.963928         0.971777      0.945271   \n",
       "32  Logistic Regression        0.871857         0.868014      0.835020   \n",
       "\n",
       "    f1_score  \n",
       "0   0.621031  \n",
       "6   0.944558  \n",
       "24  0.958341  \n",
       "32  0.851197  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classification_results = pd.concat([knn_test_max, tree_test_max, rf_test_max, lr_test_max.iloc[[0]]])\n",
    "test_classification_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundamentos_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
